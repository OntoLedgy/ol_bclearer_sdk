{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97062609-3ac3-46bc-994f-b8acf04ff074",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Requirement already satisfied: neo4j in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (5.13.0)\n",
      "Requirement already satisfied: pytz in /databricks/python3/lib/python3.10/site-packages (from neo4j) (2022.1)\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43dbfd49-018b-4c83-b4ea-450d06153bed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[34;42mbclearer_edges\u001b[0m/  \u001b[34;42mbclearer_nodes\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls /dbfs/mnt/bclearer/temp/mansoors_folder/evolve/bukom/delta/spi_v12/evolve/E3205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acac0219-f46b-4ad2-b2a8-f35823eb5592",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[34;42mbclearer_neo4j_edges\u001b[0m/  \u001b[34;42mbclearer_neo4j_nodes\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls /dbfs/mnt/bclearer/temp/mansoors_folder/evolve/bukom/delta/spi_v11/evolve/E5003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abcd2039-763e-4283-a8d9-4a3e1e0af997",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[34;42mall_edges\u001b[0m/  \u001b[34;42mall_nodes\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls /dbfs/mnt/bclearer/temp/mansoors_folder_neo4j_output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8860826c-f99a-43b1-8e18-b01c671e83d1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32ffb994-29ef-4fb3-8901-9edc2ebe5d34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "IP_ADDRESS = \"10.1.0.5\"  # 20.76.138.131 RCC, 10.1.0.5 local\n",
    "DATABASE_USERNAME = \"neo4j\"\n",
    "DATABASE_PASSWORD = \"\"\n",
    "DATABASE_CONNECTION_URL = f\"bolt://{IP_ADDRESS}:7687\"\n",
    "# DATA_CORE_PATH = \"/mnt/bclearer/temp/mansoors_folder/evolve/bukom/delta/spi_v12/evolve/E3205\"  #Iteration\n",
    "# FILE_BASENAME = \"bclearer\"\n",
    "DATA_CORE_PATH = \"/mnt/bclearer/temp/mansoors_folder/evolve/bukom/delta/spi_v11/evolve/E5003\"  # Iteration\n",
    "FILE_BASENAME = \"bclearer_neo4j\"\n",
    "DATABASE = \"pbsv11E5003\"\n",
    "NEO4J_WEBAPP = f\"http://{IP_ADDRESS}:7474/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "838b4ace-3e50-4c25-ac13-41b557e630ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "264a17b0-195f-4e36-b558-1c6464eace26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import *\n",
    "# from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24c8088c-e303-4e25-be10-471c15ea51eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from pyspark.sql import DataFrame, SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "324d094f-dd6a-44d3-a925-a989495701d1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#Delete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59441ff3-1564-47a3-bf3d-0f5636234c35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AUTH = (DATABASE_USERNAME, DATABASE_PASSWORD)\n",
    "\n",
    "\n",
    "def delete_database(db_name: str):\n",
    "    with GraphDatabase.driver(DATABASE_CONNECTION_URL, auth=AUTH) as driver:\n",
    "        driver.execute_query(\n",
    "            \"DROP DATABASE $db IF EXISTS\",\n",
    "            db=db_name,\n",
    "        )\n",
    "\n",
    "\n",
    "def create_database(db_name: str):\n",
    "    with GraphDatabase.driver(DATABASE_CONNECTION_URL, auth=AUTH) as driver:\n",
    "        driver.execute_query(\n",
    "            \"CREATE DATABASE $db IF NOT EXISTS\",\n",
    "            db=db_name,\n",
    "        )\n",
    "\n",
    "\n",
    "# Deletes all information within a database\n",
    "def delete_nodes_edges(db_name: str):\n",
    "    with GraphDatabase.driver(DATABASE_CONNECTION_URL, auth=AUTH) as driver:\n",
    "        driver.execute_query(\n",
    "            \"\"\"\n",
    "            MATCH (n)\n",
    "            DETACH DELETE n\n",
    "            \"\"\",\n",
    "            database_=db_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24084619-66e3-4cbd-b407-3381aa14fb69",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86c54eac-994c-4bfe-99d1-4bdc36fb4515",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_dataframe(\n",
    "    path: \"str\",\n",
    ") -> \"DataFrame\":\n",
    "    return spark.read.format(\"delta\").load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4675b57-a18a-47f1-84ca-d6ebda271e1a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#Load nodes and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b71e194b-5aaf-4f8b-9083-fa6c30bc4cb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nodes_df = load_dataframe(f\"{DATA_CORE_PATH}/{FILE_BASENAME}_nodes\")\n",
    "edges_df = load_dataframe(f\"{DATA_CORE_PATH}/{FILE_BASENAME}_edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d169e3d-51b2-4fe6-a3ba-252cfe6e25e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#Save data to neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3e3bcd1-b621-4387-8b93-323555791c7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "delete_database(DATABASE)\n",
    "create_database(DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7035d7b-37ae-4101-a943-57dbee7f5442",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Building our SparkSession\n",
    "spark = SparkSession.builder.appName(\"bukom-Shell-POC\").getOrCreate()\n",
    "\n",
    "# this block I want to manipulate the data so that I have dataframes containing the different types in one data frame for nodes and also for edges I want to separate dataframes that has same rels\n",
    "column_name_node = \"type\"\n",
    "column_name_edge = \"relation_type\"\n",
    "\n",
    "split_node_df = {}\n",
    "split_edge_df = {}\n",
    "\n",
    "distinct_values = [\n",
    "    row[column_name_node]\n",
    "    for row in nodes_df.select(column_name_node).distinct().collect()\n",
    "]\n",
    "\n",
    "for type_value in distinct_values:\n",
    "    new_df = nodes_df.filter(nodes_df[\"type\"] == type_value)\n",
    "    if type_value not in split_node_df:\n",
    "        split_node_df[type_value] = [new_df]\n",
    "    else:\n",
    "        split_node_df[type_value].append(new_df)\n",
    "\n",
    "distinct_values = [\n",
    "    row[column_name_edge]\n",
    "    for row in edges_df.select(column_name_edge).distinct().collect()\n",
    "]\n",
    "\n",
    "for type_value in distinct_values:\n",
    "    new_df = edges_df.filter(edges_df[\"relation_type\"] == type_value)\n",
    "    if type_value not in split_edge_df:\n",
    "        split_edge_df[type_value] = [new_df]\n",
    "    else:\n",
    "        split_edge_df[type_value].append(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c0572b9-69dc-4b87-a082-9ab871757b67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataFrame[source_primary_key_hash: string, name: string, description: string, type: string, source_system: string, stringified_aliases: array<string>, universe: string]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_node_df[\"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7a19bf8-c02a-4107-af65-45bccb5dc201",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_tag = split_node_df.get(\"tag\")\n",
    "df_tag = reduce(DataFrame.unionAll, df_tag)\n",
    "\n",
    "df_plant = split_node_df.get(\"plant\")\n",
    "df_plant = reduce(DataFrame.unionAll, df_plant)\n",
    "\n",
    "df_site = split_node_df.get(\"site\")\n",
    "df_site = reduce(DataFrame.unionAll, df_site)\n",
    "\n",
    "df_pu = split_node_df.get(\"process_unit\")\n",
    "df_pu = reduce(DataFrame.unionAll, df_pu)\n",
    "\n",
    "df_issues = split_node_df.get(\"issues\")\n",
    "df_issues = reduce(DataFrame.unionAll, df_issues)\n",
    "\n",
    "df_issue_type = split_node_df.get(\"issue_type\")\n",
    "df_issue_type = reduce(DataFrame.unionAll, df_issue_type)\n",
    "\n",
    "df_refinery = split_node_df.get(\"refinery\")\n",
    "df_refinery = reduce(DataFrame.unionAll, df_refinery)\n",
    "\n",
    "\n",
    "df_same_as = split_edge_df.get(\"SAME_AS\")\n",
    "df_same_as = reduce(DataFrame.unionAll, df_same_as)\n",
    "\n",
    "df_whole_part = split_edge_df.get(\"WHOLE_PART\")\n",
    "df_whole_part = reduce(DataFrame.unionAll, df_whole_part)\n",
    "\n",
    "df_has_issue = split_edge_df.get(\"HAS_ISSUE\")\n",
    "df_has_issue = reduce(DataFrame.unionAll, df_has_issue)\n",
    "\n",
    "df_has_issue_type = split_edge_df.get(\"HAS_ISSUE_TYPE\")\n",
    "df_has_issue_type = reduce(DataFrame.unionAll, df_has_issue_type)\n",
    "\n",
    "# drop the type column\n",
    "df_tag = df_tag.drop(\"type\")\n",
    "df_plant = df_plant.drop(\"type\")\n",
    "df_site = df_site.drop(\"type\")\n",
    "df_pu = df_pu.drop(\"type\")\n",
    "df_issues = df_issues.drop(\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41a2a244-57be-4fc2-9174-1bc5c1f9188a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_tag.write.format(\"org.neo4j.spark.DataSource\").mode(\"overwrite\").option(\n",
    "    \"url\",\n",
    "    DATABASE_CONNECTION_URL,\n",
    ").option(\"authentication.basic.username\", DATABASE_USERNAME).option(\n",
    "    \"authentication.basic.password\",\n",
    "    DATABASE_PASSWORD,\n",
    ").option(\"database\", DATABASE).option(\"labels\", \"Entity:Tag\").option(\n",
    "    \"node.keys\",\n",
    "    \"source_primary_key_hash\",\n",
    ").option(\n",
    "    \"script\",\n",
    "    \"\"\"CREATE CONSTRAINT IF NOT EXISTS FOR (tag:Tag) REQUIRE tag.source_primary_key_hash IS UNIQUE;\n",
    "                        CREATE INDEX IF NOT EXISTS FOR (entity:Entity) ON entity.source_primary_key_hash;\"\"\",\n",
    ").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae8d716d-a641-4989-bc81-f2c5067f6c70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_plant.write.format(\"org.neo4j.spark.DataSource\").mode(\"overwrite\").option(\n",
    "    \"url\",\n",
    "    DATABASE_CONNECTION_URL,\n",
    ").option(\"authentication.basic.username\", DATABASE_USERNAME).option(\n",
    "    \"authentication.basic.password\",\n",
    "    DATABASE_PASSWORD,\n",
    ").option(\"database\", DATABASE).option(\"labels\", \"Entity:Plant\").option(\n",
    "    \"node.keys\",\n",
    "    \"source_primary_key_hash\",\n",
    ").option(\n",
    "    \"script\",\n",
    "    \"\"\"CREATE CONSTRAINT IF NOT EXISTS FOR (plant:Plant) REQUIRE plant.source_primary_key_hash IS UNIQUE;\"\"\",\n",
    ").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69149242-a635-4a62-be0f-607a4b25f63c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_site.write.format(\"org.neo4j.spark.DataSource\").mode(\"overwrite\").option(\n",
    "    \"url\",\n",
    "    DATABASE_CONNECTION_URL,\n",
    ").option(\"authentication.basic.username\", DATABASE_USERNAME).option(\n",
    "    \"authentication.basic.password\",\n",
    "    DATABASE_PASSWORD,\n",
    ").option(\"database\", DATABASE).option(\"labels\", \"Entity:Site\").option(\n",
    "    \"node.keys\",\n",
    "    \"source_primary_key_hash\",\n",
    ").option(\n",
    "    \"script\",\n",
    "    \"\"\"CREATE CONSTRAINT IF NOT EXISTS FOR (s:Site) REQUIRE s.source_primary_key_hash IS UNIQUE;\"\"\",\n",
    ").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "799cb721-b409-441b-a6cc-33c6ee753125",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pu.write.format(\"org.neo4j.spark.DataSource\").mode(\"overwrite\").option(\n",
    "    \"url\",\n",
    "    DATABASE_CONNECTION_URL,\n",
    ").option(\"authentication.basic.username\", DATABASE_USERNAME).option(\n",
    "    \"authentication.basic.password\",\n",
    "    DATABASE_PASSWORD,\n",
    ").option(\"database\", DATABASE).option(\"labels\", \"Entity:ProcessUnit\").option(\n",
    "    \"node.keys\",\n",
    "    \"source_primary_key_hash\",\n",
    ").option(\n",
    "    \"script\",\n",
    "    \"\"\"CREATE CONSTRAINT IF NOT EXISTS FOR (pu:ProcessUnit) REQUIRE pu.source_primary_key_hash IS UNIQUE;\"\"\",\n",
    ").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e717e5bd-1e88-409d-9258-87ccf2e252d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_issues.write.format(\"org.neo4j.spark.DataSource\").mode(\"overwrite\").option(\n",
    "    \"url\",\n",
    "    DATABASE_CONNECTION_URL,\n",
    ").option(\"authentication.basic.username\", DATABASE_USERNAME).option(\n",
    "    \"authentication.basic.password\",\n",
    "    DATABASE_PASSWORD,\n",
    ").option(\"database\", DATABASE).option(\"labels\", \"Entity:Issue\").option(\n",
    "    \"node.keys\",\n",
    "    \"source_primary_key_hash\",\n",
    ").option(\n",
    "    \"script\",\n",
    "    \"\"\"CREATE CONSTRAINT IF NOT EXISTS FOR (issue:Issue) REQUIRE issue.source_primary_key_hash IS UNIQUE;\"\"\",\n",
    ").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34a92ca2-9638-4db7-a23a-381f12247838",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_issue_type.write.format(\"org.neo4j.spark.DataSource\").mode(\"overwrite\").option(\n",
    "    \"url\",\n",
    "    DATABASE_CONNECTION_URL,\n",
    ").option(\"authentication.basic.username\", DATABASE_USERNAME).option(\n",
    "    \"authentication.basic.password\",\n",
    "    DATABASE_PASSWORD,\n",
    ").option(\"database\", DATABASE).option(\"labels\", \"Entity:IssueType\").option(\n",
    "    \"node.keys\",\n",
    "    \"source_primary_key_hash\",\n",
    ").option(\n",
    "    \"script\",\n",
    "    \"\"\"CREATE CONSTRAINT IF NOT EXISTS FOR (issueType:IssueType) REQUIRE issueType.source_primary_key_hash IS UNIQUE;\"\"\",\n",
    ").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "040821e4-a6f8-4fe1-a1e0-f6b69f48b650",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_refinery.write.format(\"org.neo4j.spark.DataSource\").mode(\"overwrite\").option(\n",
    "    \"url\",\n",
    "    DATABASE_CONNECTION_URL,\n",
    ").option(\"authentication.basic.username\", DATABASE_USERNAME).option(\n",
    "    \"authentication.basic.password\",\n",
    "    DATABASE_PASSWORD,\n",
    ").option(\"database\", DATABASE).option(\"labels\", \"Entity:Refinery\").option(\n",
    "    \"node.keys\",\n",
    "    \"source_primary_key_hash\",\n",
    ").option(\n",
    "    \"script\",\n",
    "    \"\"\"CREATE CONSTRAINT IF NOT EXISTS FOR (refinery:Refinery) REQUIRE refinery.source_primary_key_hash IS UNIQUE;\"\"\",\n",
    ").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9184dcd-ebc0-4d40-aa62-db0544d0e53f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_same_as.repartition(1).write.format(\"org.neo4j.spark.DataSource\").mode(\n",
    "    \"append\",\n",
    ").option(\"url\", DATABASE_CONNECTION_URL).option(\n",
    "    \"authentication.basic.username\",\n",
    "    DATABASE_USERNAME,\n",
    ").option(\"authentication.basic.password\", DATABASE_PASSWORD).option(\n",
    "    \"database\",\n",
    "    DATABASE,\n",
    ").option(\n",
    "    \"query\",\n",
    "    \"\"\" MATCH (source:Entity {source_primary_key_hash: event.source}), (destination:Entity {source_primary_key_hash: event.destination}) MERGE (source)-[:SAME_AS]->(destination)\"\"\",\n",
    ").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6259d845-625f-45d0-bab3-6dabcf0eac55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_whole_part.repartition(1).write.format(\"org.neo4j.spark.DataSource\").mode(\n",
    "    \"append\",\n",
    ").option(\"url\", DATABASE_CONNECTION_URL).option(\n",
    "    \"authentication.basic.username\",\n",
    "    DATABASE_USERNAME,\n",
    ").option(\"authentication.basic.password\", DATABASE_PASSWORD).option(\n",
    "    \"database\",\n",
    "    DATABASE,\n",
    ").option(\n",
    "    \"query\",\n",
    "    \"\"\" MATCH (source:Entity {source_primary_key_hash: event.source}), (destination:Entity {source_primary_key_hash: event.destination}) MERGE (source)-[:WHOLE_PART]->(destination)\"\"\",\n",
    ").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e67b601-8184-4bf4-a7e0-d04ab16d581e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_has_issue.repartition(1).write.format(\"org.neo4j.spark.DataSource\").mode(\n",
    "    \"append\",\n",
    ").option(\"url\", DATABASE_CONNECTION_URL).option(\n",
    "    \"authentication.basic.username\",\n",
    "    DATABASE_USERNAME,\n",
    ").option(\"authentication.basic.password\", DATABASE_PASSWORD).option(\n",
    "    \"database\",\n",
    "    DATABASE,\n",
    ").option(\n",
    "    \"query\",\n",
    "    \"\"\" MATCH (source:Entity {source_primary_key_hash: event.source}), (destination:Entity {source_primary_key_hash: event.destination}) MERGE (source)-[:HAS_ISSUE]->(destination)\"\"\",\n",
    ").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60b3c19b-b7db-4114-9663-a46baccf89d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_has_issue_type.repartition(1).write.format(\"org.neo4j.spark.DataSource\").mode(\n",
    "    \"append\",\n",
    ").option(\"url\", DATABASE_CONNECTION_URL).option(\n",
    "    \"authentication.basic.username\",\n",
    "    DATABASE_USERNAME,\n",
    ").option(\"authentication.basic.password\", DATABASE_PASSWORD).option(\n",
    "    \"database\",\n",
    "    DATABASE,\n",
    ").option(\n",
    "    \"query\",\n",
    "    \"\"\" MATCH (source:Entity {source_primary_key_hash: event.source}), (destination:Entity {source_primary_key_hash: event.destination}) MERGE (source)<-[:HAS_ISSUE_TYPE]-(destination)\"\"\",\n",
    ").save()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "publish_data_to_neo4j_rafael",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
